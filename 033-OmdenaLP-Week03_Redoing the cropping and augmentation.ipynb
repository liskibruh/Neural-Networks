{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e693f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# define directory paths\n",
    "base_path = \"C-NMC_Leukemia\"\n",
    "training_data_path = os.path.join(base_path, \"training_data\")\n",
    "all_folders = [\"fold_0/all\", \"fold_1/all\", \"fold_2/all\"]\n",
    "hem_folders = [\"fold_0/hem\", \"fold_1/hem\", \"fold_2/hem\"]\n",
    "new_all_path = os.path.join(training_data_path, \"new_all\")\n",
    "new_hem_path = os.path.join(training_data_path, \"new_hem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2209b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new directories\n",
    "os.makedirs(new_all_path, exist_ok=True)\n",
    "os.makedirs(new_hem_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b19f26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files moved successfully.\n"
     ]
    }
   ],
   "source": [
    "# move all image files from 'all' folders to 'new_all' directory\n",
    "for folder_path in all_folders:\n",
    "    folder = os.path.join(training_data_path, folder_path)\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        shutil.move(file_path, new_all_path)\n",
    "        \n",
    "print(\"Image files moved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206a5d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files moved successfully.\n"
     ]
    }
   ],
   "source": [
    "# move all image files from 'hem' folders to 'new_hem' directory\n",
    "for folder_path in hem_folders:\n",
    "    folder = os.path.join(training_data_path, folder_path)\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        shutil.move(file_path, new_hem_path)\n",
    "        \n",
    "print(\"Image files moved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876532b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the empty directories after moving the images\n",
    "shutil.rmtree(training_data_path+'/fold_0')\n",
    "shutil.rmtree(training_data_path+'/fold_1')\n",
    "shutil.rmtree(training_data_path+'/fold_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6b5bc",
   "metadata": {},
   "source": [
    "# Load images into arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "987b2b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all images from disk and store them in an array\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "all_in_list=[]\n",
    "all_images_paths = os.listdir(new_all_path)\n",
    "for i, image_name in enumerate(all_images_paths):\n",
    "    if(image_name.split('.')[1] == 'bmp'):\n",
    "        image = io.imread(new_all_path+'/'+image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((150,150)) #150x150\n",
    "        all_in_list.append(np.array(image))\n",
    "all_in_array = np.array(all_in_list)\n",
    "\n",
    "del all_in_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6af0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Hem images from disk and store them in an array\n",
    "hem_in_list=[]\n",
    "hem_images_paths = os.listdir(new_hem_path)\n",
    "for i, image_name in enumerate(hem_images_paths):\n",
    "    if(image_name.split('.')[1] == 'bmp'):\n",
    "        image = io.imread(new_hem_path+'/'+image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((150,150)) #150x150\n",
    "        hem_in_list.append(np.array(image))\n",
    "hem_in_array = np.array(hem_in_list)\n",
    "\n",
    "del hem_in_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2589f895",
   "metadata": {},
   "source": [
    "# Crop all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ee2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "import cv2 as cv\n",
    "\n",
    "def crop_imgs(images_array):\n",
    "    cropped_images_in_list=[]\n",
    "    for each_image in images_array:\n",
    "        gray = cv.cvtColor(each_image, cv.COLOR_BGR2GRAY)\n",
    "        thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1] # threshold \n",
    "        hh, ww = thresh.shape\n",
    "        thresh[hh-3:hh, 0:ww] = 0 # make bottom 2 rows black where they are white the full width of the image\n",
    "        white = np.where(thresh==255) # get bounds of white pixels\n",
    "        xmin, ymin, xmax, ymax = np.min(white[1]), np.min(white[0]), np.max(white[1]), np.max(white[0])       \n",
    "        crop = each_image[ymin:ymax+3, xmin:xmax] # crop the image at the bounds adding back the two blackened rows at the bottom\n",
    "        resized_img = resize(crop, (125, 125), anti_aliasing=True)\n",
    "        cropped_images_in_list.append(resized_img) #append cropped image to list\n",
    "    \n",
    "    cropped_images_in_array=np.array(cropped_images_in_list) #convert cropped images list to array\n",
    "    del cropped_images_in_list\n",
    "    return cropped_images_in_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a875e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_all_in_array = crop_imgs(all_in_array)\n",
    "cropped_hem_in_array = crop_imgs(hem_in_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4523e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_in_array\n",
    "del hem_in_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574430e",
   "metadata": {},
   "source": [
    "# Preparing Images for Augmentation\n",
    "\n",
    "## Split the image arrays into training and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a61bb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_hem, x_test_hem = train_test_split(cropped_hem_in_array, test_size=0.1, random_state=42)\n",
    "x_train_all, x_test_all = train_test_split(cropped_all_in_array, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa54d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "del cropped_hem_in_array\n",
    "del cropped_all_in_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8eaa91",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cdb35",
   "metadata": {},
   "source": [
    "## Perform augmentation on training hem images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4848c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an ImageDataGenerator object for data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=35,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='reflect'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14a43d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the augmented images and store them in a numpy array\n",
    "augmented_x_train_hem = np.array([datagen.random_transform(img) for img in x_train_hem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb99327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_hem = np.concatenate((x_train_hem, augmented_x_train_hem), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d9d3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del augmented_x_train_hem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "176548af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6100, 5817)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_hem), len(x_train_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c6c3f",
   "metadata": {},
   "source": [
    "## Generate labels for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2779916",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hem = np.zeros((len(x_train_hem),), dtype=int)\n",
    "y_train_all = np.ones((len(x_train_all),), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3cef9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hem = np.zeros((len(x_test_hem),), dtype=int)\n",
    "y_test_all = np.ones((len(x_test_all),), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1d719",
   "metadata": {},
   "source": [
    "# Preparing data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27aec5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6100, 5817)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_hem), len(x_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6499202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train_hem, x_train_all), axis=0)\n",
    "y_train = np.concatenate((y_train_hem, y_train_all), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1aa85c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train_hem\n",
    "del x_train_all\n",
    "del y_train_hem\n",
    "del y_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1327105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.concatenate((x_test_hem, x_test_all), axis=0)\n",
    "y_test = np.concatenate((y_test_hem, y_test_all), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adbc9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_test_hem\n",
    "del x_test_all\n",
    "del y_test_hem\n",
    "del y_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa7197d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[6099], y_train[6100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbcd484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dbaae4",
   "metadata": {},
   "source": [
    "## Making sure all the images are scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35f3b43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have pixel values between 0 and 1.\n"
     ]
    }
   ],
   "source": [
    "for img in x_train:\n",
    "    if np.max(img) > 1:\n",
    "        print(\"Found an image with pixel values greater than 1.\")\n",
    "        break\n",
    "else:\n",
    "    print(\"All images have pixel values between 0 and 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6b95f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have pixel values between 0 and 1.\n"
     ]
    }
   ],
   "source": [
    "for img in x_test:\n",
    "    if np.max(img) > 1:\n",
    "        print(\"Found an image with pixel values greater than 1.\")\n",
    "        break\n",
    "else:\n",
    "    print(\"All images have pixel values between 0 and 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9618b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 125, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0902ffd",
   "metadata": {},
   "source": [
    "# Transfer Learning for Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9ea45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(125,125,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "189adcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 125, 125, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 125, 125, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 125, 125, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 62, 62, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 62, 62, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 62, 62, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 31, 31, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 31, 31, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 31, 31, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 31, 31, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 15, 15, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 15, 15, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 7, 7, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 7, 7, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 7, 7, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in VGG_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "VGG_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62bed87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373/373 [==============================] - 569s 2s/step\n",
      "57/57 [==============================] - 86s 2s/step\n"
     ]
    }
   ],
   "source": [
    "x_train_feats = VGG_model.predict(x_train)\n",
    "x_train_features = x_train_feats.reshape(x_train_feats.shape[0], -1)\n",
    "\n",
    "x_test_feats = VGG_model.predict(x_test)\n",
    "x_test_features = x_test_feats.reshape(x_test_feats.shape[0], -1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb48492",
   "metadata": {},
   "source": [
    "# Save extracted features in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f8080fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert the feature vectors to Pandas DataFrames\n",
    "train_df = pd.DataFrame(x_train_features)\n",
    "test_df = pd.DataFrame(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4ddaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the labels to the DataFrames\n",
    "train_df['label'] = y_train\n",
    "test_df['label'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d7b1a1",
   "metadata": {},
   "source": [
    "# Save dataframes to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92b1b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train_data.pickle', 'wb') as f:\n",
    "    pickle.dump(train_df, f)\n",
    "    \n",
    "with open('test_data.pickle', 'wb') as f:\n",
    "    pickle.dump(test_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b3dd6305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6100\n",
       "1    5817\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "188c3f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1455\n",
       "0     339\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
